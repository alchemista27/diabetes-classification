# Import libraries
import pandas as pd
import numpy as np
import seaborn as sns
from matplotlib import pyplot as plt


# Load dataset
dff = pd.read_csv('diabetes_dataset00.csv')
dff.head()


# Check shape and missing value
print(dff.shape)

dff.info()


# Separate target and feature
features_dff = dff.iloc[:,1:]
target_dff = dff['Target']


# Import label encoder and standard scaler
from sklearn.preprocessing import LabelEncoder, StandardScaler

encoder = LabelEncoder()
scaler = StandardScaler()

## Select categorical dtypes columns
cat_dff = features_dff.select_dtypes(include='object')
cat_cols = list(cat_dff.columns)

## Encode the categorical columns
for col in cat_cols:
    features_dff[col] = encoder.fit_transform(features_dff[col])

features_dff.head()

## Select numeric columns
num_dff = features_dff.select_dtypes(include='number')
num_cols = list(num_dff.columns)

## Scale the numeric dtypes
for col in num_cols:
    features_dff[col] = scaler.fit_transform(features_dff[[col]])

features_dff.head()


# Import PCA
from sklearn.decomposition import PCA

pca = PCA()

## Fit pca to features dff
pca.fit(features_dff)

## Check explained variance ratio
explained_var_ratio = pca.explained_variance_ratio_
explained_var_ratio

## Make dataframe
var_ratio_dff = pd.DataFrame({'features':list(features_dff.columns), 'variance_ratio':explained_var_ratio})

plt.figure(figsize=(12,8))
sns.barplot(data=var_ratio_dff, x='features', y='variance_ratio', errorbar=('ci', False))
plt.xticks(rotation=90)
plt.tight_layout()
plt.show()


# Preparing target and features
from sklearn.model_selection import GridSearchCV, train_test_split

X = np.array(features_dff)
y = np.array(target_dff)

## Set random state
SEED = 42

## Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=SEED)


# Import model
from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_estimators=300)

## Fitting the model
rf.fit(X_train, y_train)


## Predict the test set
y_predict = rf.predict(X_test)


## Measure model quality
from sklearn.metrics import accuracy_score, classification_report

accuracy = accuracy_score(y_test, y_predict)
report = classification_report(y_test, y_predict)

print('The model accuracy is', accuracy)
print(report)


## Try other classifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier

svc = SVC()
knn = KNeighborsClassifier()
dt = DecisionTreeClassifier()


## Make a dictionary of model
model_dict = {'svc':svc, 'knn':knn, 'decisiontree':dt}

for keys, item in model_dict.items():
    model_dict[keys].fit(X_train, y_train)
    y_pred = model_dict[keys].predict(X_test)
    # Calculate the accuracy
    accuracy = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred)
    print('The accuracy of model '+keys+' is', accuracy)
    print(report)



